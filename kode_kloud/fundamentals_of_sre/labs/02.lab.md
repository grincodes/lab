# Lab 2
Building and monitoring dashbaord

# Overview
info
BUILDING A MONITORING DASHBOARD LAB



Learning Outcomes of the Lab

In this lab, you will:

-> Implement Prometheus monitoring by exposing and collecting FastAPI application metrics

-> Configure Prometheus to scrape and store metrics from multiple services

-> Create and customize Grafana dashboards to visualize application performance and system health

-> Define and implement Service Level Indicators (SLIs) and Service Level Objectives (SLOs) to measure reliability and performance

-> Simulate and analyze traffic patterns to evaluate monitoring effectiveness and alerting capabilities



To start working with the monitoring-enabled web application project, you’ll need a copy of its codebase.

Your task is to:

Clone the kodekloud-records-store-web-app repository to terminal

Repository link:
https://github.com/kodekloudhub/kodekloud-records-store-web-app.git




Ensure that the FastAPI application correctly exposes Prometheus-compatible metrics at /metrics.

Step 1: Navigate to the Project Directory

cd /root/kodekloud-records-store-web-app/

Step 2: Verify Prometheus Metrics in FastAPI

Open the FastAPI files located at /root/kodekloud-records-store-web-app-main/src/api/main.py and /root/kodekloud-records-store-web-app-main/src/api/metrics.py.

Identify the code block that exposes the /metrics endpoint for Prometheus metrics.

Confirm that the following metrics are defined and functioning correctly:

http_requests_total: A Counter that tracks the total number of HTTP requests, with labels for method, route, and status_code

http_request_duration_seconds: A Histogram measuring the duration of requests, with labels for method and route

http_errors_total: A Counter that tracks HTTP request errors, with labels for method, route, and status_code for errors

Step 3: Start the Application Using Docker Compose

A. Set Up Environment Variables
Execute the environment setup script to create .env.dev with safe defaults

./deploy/environments/setup-local-env.sh

Verify the creation of the environment file

cat /root/kodekloud-records-store-web-app/deploy/environments/.env.dev

The setup script generates a .env.dev file containing the environment configuration.

B. Start the Complete Stack
Begin all services (application + observability)

docker-compose --env-file deploy/environments/.env.dev up -d

Check that all services are running

docker-compose ps

Step 4: Test the Metrics Endpoint

Click the "Application" button in the top panel to access the application at Port 8000.
Navigate to the /metrics endpoint by appending '/metrics' to the application’s URL.
For instance, if the application is running at:

https://8000-port-zj7g53hnw74da6ov.labs.kodekloud.com

Then, access the following:

https://8000-port-zj7g53hnw74da6ov.labs.kodekloud.com/metrics

OR
Execute the following command in the terminal:

curl http://localhost:8000/metrics

Step 5: Ensure Prometheus-Compatible Metrics Are Present

Verify that your custom metrics are available at the /metrics endpoint:

http_requests_total
# HELP kodekloud_http_requests_total Total number of HTTP requests received
# TYPE kodekloud_http_requests_total counter
kodekloud_http_requests_total{method="GET",route="/health",status_code="200"} 4.0
kodekloud_http_requests_total{method="GET",route="/metrics",status_code="200"} 3.0
kodekloud_http_requests_total{method="GET",route="/",status_code="200"} 1.0

http_request_duration_seconds
# HELP kodekloud_http_request_duration_seconds Time spent processing HTTP requests in seconds
# TYPE kodekloud_http_request_duration_seconds histogram
kodekloud_http_request_duration_seconds_bucket{le="0.005",method="GET",route="/health"} 4.0
kodekloud_http_request_duration_seconds_bucket{le="0.01",method="GET",route="/health"} 4.0
kodekloud_http_request_duration_seconds_bucket{le="0.025",method="GET",route="/health"} 4.0
kodekloud_http_request_duration_seconds_bucket{le="0.05",method="GET",route="/health"} 4.0
kodekloud_http_request_duration_seconds_bucket{le="0.075",method="GET",route="/health"} 4.0
kodekloud_http_request_duration_seconds_bucket{le="0.1",method="GET",route="/health"} 4.0
kodekloud_http_request_duration_seconds_bucket{le="0.25",method="GET",route="/health"} 4.0
kodekloud_http_request_duration_seconds_bucket{le="0.5",method="GET",route="/health"} 4.0
.....
.....
.....

http_errors_total
# HELP kodekloud_http_errors_total Total number of HTTP errors
# TYPE kodekloud_http_errors_total counter


Note:
If you see warnings such as:
The "POSTGRES_HOST" variable is not set. Defaulting to a blank string.
it means Docker Compose didn’t load your environment variables correctly.

Fix:
Navigate to the project directory and reload the environment variables before re-running Docker Compose:

cd /root/kodekloud-records-store-web-app-main
set -a ; source deploy/environments/.env.dev ; set +a
docker-compose ps

This ensures all environment variables from .env.dev are properly exported and recognized by Docker Compose.

########################

Ensure that Prometheus is correctly scraping metrics from both the FastAPI service and Celery worker service.

Step 1: Open Prometheus Configuration

Open the file prometheus.yml present at location /root/kodekloud-records-store-web-app-main/config/monitoring/prometheus.yml and ensure the following scrape configurations exist:

scrape_configs:
  - job_name: "kodekloud-record-store-api"
    metrics_path: "/metrics"
    static_configs:
      - targets: ["api:8000"]

Note: These lines should already be included inprometheus.yml. If they are missing, please add them; if they are commented out, kindly uncomment and confirm that the indentation is correct.

Step 2: Restart Prometheus to Apply Changes

Run the following command to restart Prometheus:

docker-compose --env-file deploy/environments/.env.dev restart prometheus

Step 3: Verify Prometheus is Running

Click the "Prometheus UI" button in the top panel to open the Prometheus Web UI available on Port 9090.

Navigate to Status → Targets Health

Locate the "kodekloud-record-store-api" targets

Expected Outcome:

Targets should be in an "UP" status, meaning Prometheus is successfully scraping metrics.

If the status is "DOWN", the service might not be accessible.




########################
Ensure that Grafana automatically loads the Prometheus data source and provisions the pre-configured dashboards.

Step 1: Open Grafana’s Data Source Configuration

Check the file prometheus.yml present at location /root/kodekloud-records-store-web-app-main/config/monitoring/grafana-provisioning/datasources/prometheus.yml and ensure it includes:

apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true

Note: These lines should already be included in prometheus.yml. If they are missing, please add them; if they are commented out, kindly uncomment and confirm that the indentation is correct.

Step 2: Restart Grafana to Apply Changes

Run the following command to restart Grafana:

docker-compose --env-file deploy/environments/.env.dev restart grafana

Step 3: Verify Prometheus as a Data Source

Click the "Grafana UI" button in the top panel to open Grafana. The UI is accessible at Port 3000.

Login Credentials:

Username: admin
Password: dev_admin_123
Navigate to Grafana UI → Connections → Data Sources

Ensure Prometheus appears in the list of available data sources.

Step 4: Verify the Pre-Provisioned Grafana Dashboards

Grafana should automatically load a predefined dashboard from:

/root/kodekloud-records-store-web-app/config/monitoring/grafana-provisioning/dashboards/dashboard.yaml

To Verify in Grafana:

Go to Dashboards in the Grafana UI.

Look for the following dashboards:

"KodeKloud Records Store SLIs"

"KodeKloud Records Store SLOs"

Open one of the dashboards and confirm that it displays real-time metrics.


#####
What is the primary role of Prometheus in a monitoring pipeline?
```
Storing and querying logs through tiime series data
```


To edit the KodeKloud Record Store SLI dashboard in Grafana and include the required SLI panels, follow these steps:

Step 1: Access the KodeKloud Records Store SLIs

Log in to your Grafana instance.

Navigate to Dashboards.

Locate and open the "KodeKloud Record Store SLI Dashboard".

Step 2: Add CPU Usage/Saturation Panels

A) Time Series for CPU Usage Trends

Click on Edit -> Add -> Visualization

Name the visualization: CPU Saturation Time Series

Select Prometheus as the Data Source.

Use the following PromQL Query:

rate(process_cpu_seconds_total[5m])

Click "Run Query".

Customize Visualization Settings:

Select "Time Series" visualization.
Click "Save dashboard" → "Save".



B) Gauge Panel for Current CPU Usage

Click on Edit -> Add -> Visualization

Name the visualization: CPU Saturation Gauge

Select Prometheus as the Data Source.

Use the same PromQL Query:

rate(process_cpu_seconds_total[5m])

Click "Run Query".

Customize Visualization Settings:

Change the visualization type to "Gauge".
Click "Save dashboard" → "Save".




Note:

Grafana Login Credentials:

Username: admin
Password: dev_admin_123


############

To edit the KodeKloud Record Store SLI dashboard in Grafana and include the required SLI panels, follow these steps:

Step 1: Access the KodeKloud Record Store SLI Dashboard

Log in to your Grafana instance.

Navigate to Dashboards.

Locate and open the "KodeKloud Record Store SLI Dashboard".

Step 2: Add Latency SLI Visualization in Grafana

Click on Edit -> Add -> Visualization

Name the visualization: HTTP Request Duration by Method (p95)

Select Prometheus as the Data Source.

Use the following PromQL Query:
This query calculates the 95th percentile request duration, grouped by HTTP method.

histogram_quantile(0.95, sum(rate(kodekloud_http_request_duration_seconds_bucket[5m])) by (le, method))

Click "Run Query".

Configure Thresholds (Color Coding)
Add Threshold Values to highlight performance issues:

0.3 seconds → Yellow

0.5 seconds → Red

Standard option:

Set Standard Option Unit to seconds (s).
Customize Visualization Settings:

Select "Time Series" visualization.
Click "Save dashboard" → "Save".


##################
Enhancing the KodeKloud Record Store SLO Dashboard

Step 1: Access the KodeKloud Record Store SLO Dashboard

Log in to your Grafana instance.

Navigate to Dashboards.

Locate and open the "KodeKloud Record Store SLO Dashboard".

Step 2: Add Availability SLO Gauge Panel

Click on Edit -> Add -> Visualization

Name the visualization: Availability SLO (99.9% Target)

Select Prometheus as the Data Source.

Use the following PromQL Query:
This calculates the availability percentage over the last 30 days for the /health endpoint.

100 * avg_over_time(probe_success{endpoint="/health"}[30d])

Click "Run Query".

Configure Thresholds (Color Coding)
Add Threshold Values to highlight performance issues:

99.9% → Blue

99.8% → Yellow

99.5% → Red

Standard option:

Set Standard Option Unit to Percent (0-100).
Customize Visualization Settings:

Select "Gauge" visualization.
Click "Save dashboard" → "Save".

Expected Outcome:

The SLO dashboard now includes a gauge visualization displaying the availability percentage against the 99.9% target.

Color-coded thresholds indicate whether the system meets, is at risk, or falls below the SLO.

Check if the following panels are created: Availability SLO (99.9% Target)

###################
Key Takeaways

Monitoring Implementation:

Metrics collection starts at the application level with instrumented code.

Prometheus acts as the central metrics storage and query engine.

Grafana provides visualization and dashboarding capabilities.

Both metrics collection and visualization require careful configuration for accuracy and relevance.



Dashboard Best Practices:

Prioritize user-experienced metrics when defining SLIs and SLOs.

Choose appropriate visualization types based on the nature of the metric.

Set meaningful thresholds aligned with SLO targets.

Include both real-time and historical views for context and trend analysis.



Next Steps:

Implement alerting based on SLO thresholds to detect issues proactively.

Expand dashboards with detailed views of critical components.

Correlate metrics across different services for system-wide visibility.

Integrate log aggregation alongside metrics monitoring for deeper insights.



Remember:
Effective monitoring is about actionable insights, not just data collection. Your dashboards should tell a clear story about your application's performance and reliability.






